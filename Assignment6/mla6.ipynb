{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"iris.csv\")\n",
    "data = a.drop([\"sepal_width\",\"petal_length\"],axis =1)\n",
    "df = data.sample(frac=1)          #shuffle\n",
    "r,c = data.shape\n",
    "# reset index values\n",
    "\n",
    "xx  =df.reset_index()\n",
    "\n",
    "df = xx.iloc[:,1:4]\n",
    "kf=df.iloc[106:150,:]\n",
    "df = df.iloc[0:105,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns mean and varianc of the features\n",
    "# df = data frame with header and last column as output/classification\n",
    "\n",
    "#note : input only one type of label/class\n",
    "\n",
    "def basics(df):   \n",
    "    #data  =df.values\n",
    "    r,c = df.shape          #get sample size and features count\n",
    "    x = df.iloc[:,0:c-1]    #features\n",
    "    y = df.iloc[:,c-1]\n",
    "    #x = df.values\n",
    "    mean = []\n",
    "    var = []\n",
    "    for i in range(c-1):      # calculate mean for input features\n",
    "        m = np.mean(x.values[:,i])\n",
    "        mean.append(m)\n",
    "        \n",
    "    for i in range(c-1):   # calculate variance of each features\n",
    "        v = np.var(x.values[:,i])\n",
    "        var.append(v)\n",
    "        \n",
    "    return mean,var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function pandas dataframe as input (have features and labels)\n",
    "#returns \n",
    "\n",
    "def class_separator(df):\n",
    "    r,c = df.shape\n",
    "    dt1 =[]\n",
    "    dt2 = []\n",
    "    dt3 =[]\n",
    "    y_cls = df.iloc[:,c-1].unique()            #get all classifier/different output\n",
    "    l = len(y_cls)    # count of different label\n",
    "    for i in range(r):  #iterate over each sample/row\n",
    "        if df.iloc[i,c-1] == y_cls[0]:\n",
    "            dt  = df.iloc[i,0:c]\n",
    "            dt1.append(dt)\n",
    "            \n",
    "        elif df.iloc[i,c-1] == y_cls[1]:\n",
    "            dtm = df.iloc[i,0:c]\n",
    "            dt2.append(dtm)\n",
    "            \n",
    "        elif df.iloc[i,c-1] == y_cls[2]:\n",
    "            dti = df.iloc[i,0:c]\n",
    "            dt3.append(dti)\n",
    "            \n",
    "            \n",
    "    return pd.DataFrame(dt1),pd.DataFrame(dt2),pd.DataFrame(dt3)\n",
    "                \n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = 1*2 array having mean values of each features\n",
    "#var = 1*2 array having variance of each features\n",
    "# x = [x1,x2]     features values to be predicted\n",
    "def basic_prob(mean,var,x):\n",
    "    l = len(mean)\n",
    "    p = 1\n",
    "    for i in range(l):\n",
    "        a = 2*(math.pi)*(np.square(var[i])) \n",
    "        b = ((x[i] - mean[i])**2)/(2*np.square(var[i]))\n",
    "        c = np.exp(-1*b)\n",
    "        p = p * ((a**(-0.5))*c)       #gaussian\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [sepal_length,petal_width]\n",
    "#df = [sepal_lengh,petal_width,label]\n",
    "\n",
    "def main(df,x):\n",
    "    r,c = df.shape\n",
    "    y_cls = df.iloc[:,c-1].unique()  \n",
    "    y_cls[0],y_cls[1],y_cls[2] = class_separator(df)   # get separate data for each classifier\n",
    "    r,c = df.shape\n",
    "    r1,c1 = y_cls[0].shape\n",
    "    r2,c2 = y_cls[1].shape\n",
    "    r3,c3 = y_cls[2].shape\n",
    "    \n",
    "    # calculate the probability of each classifier in training set\n",
    "    \n",
    "    \n",
    "    #calculate mean and variance of each labels\n",
    "    \n",
    "    mean1,var1  = basics(y_cls[0])\n",
    "    mean2,var2  = basics(y_cls[1])\n",
    "    mean3,var3 = basics(y_cls[2])\n",
    "    \n",
    "    # calculate probailities for each lables w.r.to given points (only numerator, as denominator remains same for all)\n",
    "    \n",
    "    # calculate prob. of setosa\n",
    "    \n",
    "    prob1 = (r1/r)*basic_prob(mean1,var1,x)\n",
    "    prob2 = (r2/r)*basic_prob(mean2,var2,x)\n",
    "    prob3 = (r3/r)*basic_prob(mean3,var3,x)\n",
    "    \n",
    "    return prob1,prob2,prob3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(df,x):\n",
    "    r,c = df.shape\n",
    "    #print(\"The given features represents:\")\n",
    "    prob = main(df,x)    # get the probabilities values\n",
    "    ind = np.argmax(prob)\n",
    "    label =df.iloc[:,c-1].unique()\n",
    "    out = label[ind]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_matrix(train_df,pool_df):\n",
    "    r,c = pool_df.shape\n",
    "    pre = []\n",
    "    for i in range(r):\n",
    "        m = prediction(train_df,pool_df.iloc[i,0:2])\n",
    "        pre.append(m)\n",
    "        \n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data used for prediction (with label)\n",
    "#pre = predicted data (only label)\n",
    "\n",
    "#pre = prediction_matrix(df,df)\n",
    "\n",
    "\n",
    "def accuracy(actual,pre):\n",
    "    r = len(pre)           #total cases/count for prediction\n",
    "    #actual_label = actual.iloc[:,-1]\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(r):\n",
    "        if actual.iloc[i,-1] == pre[i]:\n",
    "            count = count + 1\n",
    "            \n",
    "    acc = (count/r)*100\n",
    "            \n",
    "    return acc\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.9090909090909"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = prediction_matrix(df,kf)\n",
    "accuracy(kf,pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.b\n",
    "import matplotlib.pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data splitting into test,train and pool\n",
    "\n",
    "\n",
    "r,c = df.shape\n",
    "a =round(r*0.1)\n",
    "b = round(r*0.6)    # count of pool set samples\n",
    "\n",
    "\n",
    "train_df1 = df.iloc[0:a,:]       #10%\n",
    "pool_df1 = df.iloc[a:a+b+1,:]    #60%\n",
    "test_df1 = df.iloc[a+b+1:,:]     #30%\n",
    "\n",
    "\n",
    "xx  =df.reset_index()\n",
    "\n",
    "df = xx.iloc[:,1:4]\n",
    "\n",
    "\n",
    "# resetting the index of train,pool and test dataframes\n",
    "xx1 = train_df1.reset_index()\n",
    "train_df = xx1.iloc[:,1:4]\n",
    "\n",
    "\n",
    "xx2 = pool_df1.reset_index()\n",
    "pool_df = xx2.iloc[:,1:4]\n",
    "\n",
    "\n",
    "xx3 = test_df1.reset_index()\n",
    "test_df = xx3.iloc[:,1:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainity_index(train_df,pool_df):\n",
    "    r,c = pool_df.shape\n",
    "    prob1 = []\n",
    "    prob2 = []\n",
    "    prob3 = []\n",
    "    for i in range(r):\n",
    "        p,q,r = main(train_df,pool_df.iloc[i,0:2])\n",
    "        prob1.append(p)\n",
    "        prob2.append(q)\n",
    "        prob3.append(r)\n",
    "        \n",
    "    t1 = np.argmin(prob1)\n",
    "    t2 = np.argmin(prob2)\n",
    "    t3 = np.argmin(prob3)\n",
    "    \n",
    "    ind = min(np.array([t1,t2,t3]))\n",
    "    \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The uncertainity index is :\n",
      "0\n",
      "pool data :\n",
      "sepal_length           6.4\n",
      "petal_width            1.3\n",
      "species         versicolor\n",
      "Name: 0, dtype: object\n",
      "prediction:\n",
      "versicolor\n"
     ]
    }
   ],
   "source": [
    "print(\"The uncertainity index is :\")\n",
    "print(uncertainity_index(train_df,pool_df))\n",
    "print(\"pool data :\")\n",
    "print(pool_df.iloc[0,:])\n",
    "print(\"prediction:\")\n",
    "print(prediction(df,np.array([5.8,1.2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = uncertainity_index(train_df,pool_df)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learn(train_df,pool_df):\n",
    "    itr = 10       # itertions\n",
    "    acc = []      # stores accurancy % for each iterations\n",
    "    for i in range(itr):\n",
    "        pre = prediction_matrix(train_df,pool_df)      # predictions\n",
    "        acp = accuracy(pool_df,pre)                    #accuracy %\n",
    "        acc.append(acp)\n",
    "        \n",
    "        index  = uncertainity_index(train_df,pool_df)     #get the uncertainity index\n",
    "        #print(pool_df)\n",
    "        tt = train_df.append(pool_df.iloc[index,:])    #update train set\n",
    "        \n",
    "        #reset index\n",
    "        xx1 = tt.reset_index()\n",
    "        train_df = xx1.iloc[:,1:4]\n",
    "        \n",
    "        \n",
    "        pp = pool_df.drop([index])        #drop uncertainity row from pool data frame\n",
    "        #reset index\n",
    "        xx2 = pp.reset_index()\n",
    "        pool_df = xx2.iloc[:,1:4]\n",
    "        \n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67.1875,\n",
       " 61.904761904761905,\n",
       " 61.29032258064516,\n",
       " 63.934426229508205,\n",
       " 83.33333333333334,\n",
       " 84.7457627118644,\n",
       " 89.65517241379311,\n",
       " 96.49122807017544,\n",
       " 94.64285714285714,\n",
       " 90.9090909090909]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "acc =active_learn(train_df,pool_df)\n",
    "\n",
    "\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b.iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92.0185,\n",
       " 62.8015,\n",
       " 72.9795,\n",
       " 60.9105,\n",
       " 65.3565,\n",
       " 71.6895,\n",
       " 74.6605,\n",
       " 87.9075,\n",
       " 61.966499999999996,\n",
       " 85.7555]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "acc1 = []\n",
    "\n",
    "for j in range(10):\n",
    "    r,c = pool_df.shape\n",
    "    i = random.randint(0,r-1)\n",
    "\n",
    "    pool_df.drop(i)\n",
    "    train_df.append(pool_df.iloc[i,:]) \n",
    "    \n",
    "    pre = prediction_matrix(train_df,pool_df)\n",
    "    acc1.append( accuracy(pool_df,pre)\n",
    "    \n",
    "acc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
